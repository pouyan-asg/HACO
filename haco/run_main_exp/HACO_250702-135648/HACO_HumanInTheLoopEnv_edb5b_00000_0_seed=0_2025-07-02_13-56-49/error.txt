Failure # 1 (occurred at 2025-07-02_13-56-55)
Traceback (most recent call last):
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::HACO.train()[39m (pid=471492, ip=192.168.2.18)
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 101, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 476, in __init__
    super().__init__(config, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trainable.py", line 249, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
    self._init(self.config, self.env_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 125, in _init
    self.config["num_workers"])
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 699, in _make_workers
    logdir=self.logdir)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 74, in __init__
    self._local_config)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 305, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 437, in __init__
    policy_config["framework"]))
RuntimeError: GPUs were assigned to this worker by Ray, but your DL framework (tf) reports GPU acceleration is disabled. This could be due to a bad CUDA- or tf installation.

Failure # 2 (occurred at 2025-07-02_13-57-01)
Traceback (most recent call last):
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::HACO.train()[39m (pid=471490, ip=192.168.2.18)
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 101, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 476, in __init__
    super().__init__(config, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trainable.py", line 249, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
    self._init(self.config, self.env_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 125, in _init
    self.config["num_workers"])
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 699, in _make_workers
    logdir=self.logdir)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 74, in __init__
    self._local_config)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 305, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 437, in __init__
    policy_config["framework"]))
RuntimeError: GPUs were assigned to this worker by Ray, but your DL framework (tf) reports GPU acceleration is disabled. This could be due to a bad CUDA- or tf installation.

Failure # 3 (occurred at 2025-07-02_13-57-07)
Traceback (most recent call last):
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::HACO.train()[39m (pid=471493, ip=192.168.2.18)
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 101, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 476, in __init__
    super().__init__(config, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trainable.py", line 249, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
    self._init(self.config, self.env_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 125, in _init
    self.config["num_workers"])
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 699, in _make_workers
    logdir=self.logdir)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 74, in __init__
    self._local_config)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 305, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 437, in __init__
    policy_config["framework"]))
RuntimeError: GPUs were assigned to this worker by Ray, but your DL framework (tf) reports GPU acceleration is disabled. This could be due to a bad CUDA- or tf installation.

Failure # 4 (occurred at 2025-07-02_13-57-13)
Traceback (most recent call last):
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::HACO.train()[39m (pid=471495, ip=192.168.2.18)
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 101, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 476, in __init__
    super().__init__(config, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trainable.py", line 249, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
    self._init(self.config, self.env_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 125, in _init
    self.config["num_workers"])
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 699, in _make_workers
    logdir=self.logdir)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 74, in __init__
    self._local_config)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 305, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 437, in __init__
    policy_config["framework"]))
RuntimeError: GPUs were assigned to this worker by Ray, but your DL framework (tf) reports GPU acceleration is disabled. This could be due to a bad CUDA- or tf installation.

Failure # 5 (occurred at 2025-07-02_13-57-19)
Traceback (most recent call last):
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::HACO.train()[39m (pid=471505, ip=192.168.2.18)
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 101, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 476, in __init__
    super().__init__(config, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trainable.py", line 249, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
    self._init(self.config, self.env_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 125, in _init
    self.config["num_workers"])
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 699, in _make_workers
    logdir=self.logdir)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 74, in __init__
    self._local_config)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 305, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 437, in __init__
    policy_config["framework"]))
RuntimeError: GPUs were assigned to this worker by Ray, but your DL framework (tf) reports GPU acceleration is disabled. This could be due to a bad CUDA- or tf installation.

Failure # 6 (occurred at 2025-07-02_13-57-25)
Traceback (most recent call last):
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trial_runner.py", line 515, in _process_trial
    result = self.trial_executor.fetch_result(trial)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/ray_trial_executor.py", line 488, in fetch_result
    result = ray.get(trial_future[0], timeout=DEFAULT_GET_TIMEOUT)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/worker.py", line 1428, in get
    raise value.as_instanceof_cause()
ray.exceptions.RayTaskError(RuntimeError): [36mray::HACO.train()[39m (pid=471491, ip=192.168.2.18)
  File "python/ray/_raylet.pyx", line 445, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 479, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 483, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 484, in ray._raylet.execute_task
  File "python/ray/_raylet.pyx", line 438, in ray._raylet.execute_task.function_executor
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 101, in __init__
    Trainer.__init__(self, config, env, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 476, in __init__
    super().__init__(config, logger_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/tune/trainable.py", line 249, in __init__
    self.setup(copy.deepcopy(self.config))
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 629, in setup
    self._init(self.config, self.env_creator)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer_template.py", line 125, in _init
    self.config["num_workers"])
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/agents/trainer.py", line 699, in _make_workers
    logdir=self.logdir)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 74, in __init__
    self._local_config)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/worker_set.py", line 305, in _make_worker
    extra_python_environs=extra_python_environs)
  File "/home/pouyan/anaconda3/envs/haco/lib/python3.7/site-packages/ray/rllib/evaluation/rollout_worker.py", line 437, in __init__
    policy_config["framework"]))
RuntimeError: GPUs were assigned to this worker by Ray, but your DL framework (tf) reports GPU acceleration is disabled. This could be due to a bad CUDA- or tf installation.

